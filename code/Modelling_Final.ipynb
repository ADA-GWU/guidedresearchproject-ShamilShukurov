{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6901f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a7585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sklearn_roc_curve(y_real, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    roc_display.figure_.set_size_inches(5,5)\n",
    "    plt.plot([0, 1], [0, 1], color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2317622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Row_Count</th>\n",
       "      <th>Minority_Class_Percent</th>\n",
       "      <th>Target_Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>1477</td>\n",
       "      <td>4.520</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>32561</td>\n",
       "      <td>24.080</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churn</td>\n",
       "      <td>7043</td>\n",
       "      <td>26.530</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contraceptive</td>\n",
       "      <td>1743</td>\n",
       "      <td>22.600</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Covertype</td>\n",
       "      <td>581012</td>\n",
       "      <td>14.770</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>284807</td>\n",
       "      <td>0.172</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fraud2</td>\n",
       "      <td>650000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>is_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Letter-a</td>\n",
       "      <td>20000</td>\n",
       "      <td>3.940</td>\n",
       "      <td>letter_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Letter-vowel</td>\n",
       "      <td>20000</td>\n",
       "      <td>19.390</td>\n",
       "      <td>is_vowel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pendigits</td>\n",
       "      <td>10992</td>\n",
       "      <td>9.590</td>\n",
       "      <td>is_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sick_euthyroid</td>\n",
       "      <td>2194</td>\n",
       "      <td>10.050</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Splice-junction</td>\n",
       "      <td>3186</td>\n",
       "      <td>24.070</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wine</td>\n",
       "      <td>6497</td>\n",
       "      <td>3.760</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset_Name  Row_Count  Minority_Class_Percent Target_Column\n",
       "0           Abalone       1477                   4.520        target\n",
       "1             Adult      32561                  24.080        target\n",
       "2             Churn       7043                  26.530        target\n",
       "3     Contraceptive       1743                  22.600        target\n",
       "4         Covertype     581012                  14.770        target\n",
       "5             Fraud     284807                   0.172         Class\n",
       "6            Fraud2     650000                   0.500      is_fraud\n",
       "7          Letter-a      20000                   3.940      letter_a\n",
       "8      Letter-vowel      20000                  19.390      is_vowel\n",
       "9         Pendigits      10992                   9.590          is_9\n",
       "10   Sick_euthyroid       2194                  10.050        target\n",
       "11  Splice-junction       3186                  24.070        target\n",
       "12             Wine       6497                   3.760        target"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_di = r\"C:\\Users\\SukurovSB\\Desktop\\Guided_Research_New\\guidedresearchproject-ShamilShukurov\\data\\dataset_infos.csv\"\n",
    "dataset_infos = pd.read_csv(fp_di).drop(columns=\"Unnamed: 0\")\n",
    "dataset_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a968ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_lgbm(df_train:pd.DataFrame, \n",
    "              df_test:pd.DataFrame, \n",
    "              target_col:str,\n",
    "              dataset_name:str,\n",
    "              model_name:str=\"LGBM Baseline\",\n",
    "              message:str=\"Building LGBM Model...\"):\n",
    "    # Train data\n",
    "    X_train = df_train.drop(columns=target_col)\n",
    "    y_train = df_train[target_col]\n",
    "\n",
    "    # Test data\n",
    "    X_test = df_test.drop(columns=target_col)\n",
    "    y_test = df_test[target_col]\n",
    "\n",
    "    print(message)\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prediction_train = clf.predict(X_train)\n",
    "    prediction_test = clf.predict(X_test)\n",
    "    prediction_proba_train=clf.predict_proba(X_train)\n",
    "    prediction_proba_test=clf.predict_proba(X_test)\n",
    "\n",
    "    cr_test = classification_report(y_test,prediction_test,zero_division=True, output_dict=True)\n",
    "    f1_test = cr_test['1']['f1-score']\n",
    "    acc_test = cr_test['accuracy']\n",
    "    auc_test = roc_auc_score(y_test, prediction_proba_test[:,1])\n",
    "    cr_train = classification_report(y_train,prediction_train,zero_division=True, output_dict=True)\n",
    "    f1_train = cr_train['1']['f1-score']\n",
    "    acc_train = cr_train['accuracy']\n",
    "    auc_train = roc_auc_score(y_train, prediction_proba_train[:,1])\n",
    "\n",
    "    report = {\n",
    "        \"Dataset\":dataset_name,\n",
    "        \"Model\":model_name,\n",
    "        \"f1_test\": f1_test,\n",
    "        \"f1_train\":f1_train,\n",
    "        \"accuracy_test\" : acc_test,\n",
    "        \"accuracy_train\" :acc_train,\n",
    "        \"AUC_test\" :auc_test,\n",
    "        \"AUC_train\" :auc_train\n",
    "    }\n",
    "    print(\"ROC Curve for test data: {}\".format(auc_test))\n",
    "    plot_sklearn_roc_curve(y_test,prediction_proba_test[:,1])\n",
    "    \n",
    "    return clf, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a802cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(df_train:pd.DataFrame, \n",
    "              df_test:pd.DataFrame, \n",
    "              target_col:str, \n",
    "              dataset_name:str,\n",
    "              model_name:str=\"LGBM Upsample\",\n",
    "              message:str=\"Building LGBM Upsample Model...\"):\n",
    "    print(\"Upsampling is being applied...\")\n",
    "    df_majority = df_train[(df_train[target_col]==0)] \n",
    "    df_minority = df_train[(df_train[target_col]==1)] \n",
    "    # upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                  replace=True,    # sample with replacement\n",
    "                                  n_samples= df_majority.shape[0], # to match majority class\n",
    "                                  random_state=42)  # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_minority_upsampled, df_majority])\n",
    "    return base_lgbm(df_upsampled, df_test, target_col, dataset_name, model_name, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659735aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df_train:pd.DataFrame, \n",
    "               df_test:pd.DataFrame, \n",
    "               target_col:str, \n",
    "               dataset_name:str,\n",
    "               model_name:str=\"LGBM Downsample\",\n",
    "               message:str=\"Building LGBM Downsample Model...\"):\n",
    "    print(\"Downsampling is being applied...\")\n",
    "    df_majority = df_train[(df_train[target_col]==0)] \n",
    "    df_minority = df_train[(df_train[target_col]==1)] \n",
    "    # downsample majority class\n",
    "    df_majority_upsampled = resample(df_majority, \n",
    "                                  replace=False,    # sample with replacement\n",
    "                                  n_samples= df_minority.shape[0], # to match majority class\n",
    "                                  random_state=42)  # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_downsampled = pd.concat([df_minority, df_majority_upsampled])\n",
    "    return base_lgbm(df_downsampled, df_test, target_col, dataset_name, model_name, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e0501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_lgbm(df_train:pd.DataFrame, \n",
    "               df_test:pd.DataFrame, \n",
    "               target_col:str, \n",
    "               dataset_name:str,\n",
    "               model_name:str=\"SMOTE LGBM\",\n",
    "               message:str=\"Building SMOTE LGBM Model...\"):\n",
    "    # Train data\n",
    "    X_train = df_train.drop(columns=target_col)\n",
    "    y_train = df_train[target_col]\n",
    "    print(\"SMOTE is being applied...\")\n",
    "    # Resampling the minority class. The strategy can be changed as required.\n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "    # Fit the model to generate the data.\n",
    "    oversampled_X, oversampled_Y = sm.fit_resample(X_train, y_train)\n",
    "    oversampled = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)\n",
    "    return base_lgbm(oversampled, df_test, target_col, dataset_name, model_name, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e292ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_bagging_lgbm(df_train:pd.DataFrame, \n",
    "                          df_test:pd.DataFrame, \n",
    "                          target_col:str, \n",
    "                          dataset_name:str,\n",
    "                          model_name:str=\"LGBM Balanced Bagging\",\n",
    "                          message:str=\"Building LGBM Balanced Bagging Model...\"):\n",
    "    # Train data\n",
    "    X_train = df_train.drop(columns=target_col)\n",
    "    y_train = df_train[target_col]\n",
    "\n",
    "    # Test data\n",
    "    X_test = df_test.drop(columns=target_col)\n",
    "    y_test = df_test[target_col]\n",
    "\n",
    "    print(message)\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    classifier = BalancedBaggingClassifier(estimator=clf,\n",
    "                                  sampling_strategy='not majority',\n",
    "                                  replacement=False,\n",
    "                                  random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    prediction_proba_train=classifier.predict_proba(X_train)\n",
    "    prediction_proba_test=classifier.predict_proba(X_test)\n",
    "\n",
    "    cr_test = classification_report(y_test,prediction_test,zero_division=True, output_dict=True)\n",
    "    f1_test = cr_test['1']['f1-score']\n",
    "    acc_test = cr_test['accuracy']\n",
    "    auc_test = roc_auc_score(y_test, prediction_proba_test[:,1])\n",
    "    cr_train = classification_report(y_train,prediction_train,zero_division=True, output_dict=True)\n",
    "    f1_train = cr_train['1']['f1-score']\n",
    "    acc_train = cr_train['accuracy']\n",
    "    auc_train = roc_auc_score(y_train, prediction_proba_train[:,1])\n",
    "\n",
    "    report = {\n",
    "      \"Dataset\":dataset_name,\n",
    "      \"Model\":model_name,\n",
    "      \"f1_test\": f1_test,\n",
    "      \"f1_train\":f1_train,\n",
    "      \"accuracy_test\" : acc_test,\n",
    "      \"accuracy_train\" :acc_train,\n",
    "      \"AUC_test\" :auc_test,\n",
    "      \"AUC_train\" :auc_train\n",
    "    }\n",
    "    print(\"ROC Curve for test data: {}\".format(auc_test))\n",
    "    plot_sklearn_roc_curve(y_test,prediction_proba_test[:,1])\n",
    "    return classifier, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50182928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_imbalance(df_train:pd.DataFrame, \n",
    "                   df_test:pd.DataFrame, \n",
    "                   target_col:str, \n",
    "                   dataset_name:str,\n",
    "                   model_name:str=\"LGBM_Imbalance\",\n",
    "                   message:str=\"Building LGBM Imbalance Model...\"):\n",
    "    # Train data\n",
    "    X_train = df_train.drop(columns=target_col)\n",
    "    y_train = df_train[target_col]\n",
    "\n",
    "    # Test data\n",
    "    X_test = df_test.drop(columns=target_col)\n",
    "    y_test = df_test[target_col]  \n",
    "\n",
    "    d_train=lgb.Dataset(X_train, label=y_train)\n",
    "    d_test=lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "    parameters = {\n",
    "      'objective': 'binary',\n",
    "      'metric': 'auc',\n",
    "      'is_unbalance': 'true'\n",
    "    }\n",
    "\n",
    "    clf2 = lgb.train(params=parameters, train_set=d_train, valid_sets=d_test, verbose_eval=0)\n",
    "\n",
    "    prediction_train_proba = clf2.predict(X_train)\n",
    "    prediction_test_proba = clf2.predict(X_test)\n",
    "\n",
    "    prediction_train = np.where(prediction_train_proba>0.5,1,0)\n",
    "    prediction_test = np.where(prediction_test_proba>0.5,1,0)\n",
    "\n",
    "    cr_test = classification_report(y_test,prediction_test,zero_division=True, output_dict=True)\n",
    "    f1_test = cr_test['1']['f1-score']\n",
    "    acc_test = cr_test['accuracy']\n",
    "    auc_test = roc_auc_score(y_test, prediction_test_proba)\n",
    "    cr_train = classification_report(y_train,prediction_train,zero_division=True, output_dict=True)\n",
    "    f1_train = cr_train['1']['f1-score']\n",
    "    acc_train = cr_train['accuracy']\n",
    "    auc_train = roc_auc_score(y_train, prediction_train_proba)\n",
    "\n",
    "    report = {\n",
    "      \"Dataset\":dataset_name,\n",
    "      \"Model\":model_name,\n",
    "      \"f1_test\": f1_test,\n",
    "      \"f1_train\":f1_train,\n",
    "      \"accuracy_test\" : acc_test,\n",
    "      \"accuracy_train\" :acc_train,\n",
    "      \"AUC_test\" :auc_test,\n",
    "      \"AUC_train\" :auc_train\n",
    "    }\n",
    "    print(\"ROC Curve for test data: {}\".format(auc_test))\n",
    "    plot_sklearn_roc_curve(y_test, prediction_test_proba)\n",
    "    return clf2, report \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b05ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_experiment(df_train:pd.DataFrame, \n",
    "                     df_test:pd.DataFrame,\n",
    "                     target_col:str, \n",
    "                     dataset_name:str):\n",
    "    print(\"Running Experiment...\")\n",
    "    print(\"Dataset Name: {}\\nTarget Column: {}\".format(dataset_name, target_col))\n",
    "\n",
    "    lgbm_base_model, rep_lgbm_base = base_lgbm(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_lgbm_base_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(lgbm_base_model, f)\n",
    "\n",
    "    upsample_model, rep_upsample = upsample(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_upsample_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(upsample_model, f)\n",
    "\n",
    "    downsample_model, rep_downsample = downsample(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_downsample_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(downsample_model, f)\n",
    "\n",
    "    smote_lgbm_model, rep_smote_lgbm = smote_lgbm(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_smote_lgbm_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(smote_lgbm_model, f)\n",
    "\n",
    "    balanced_bagging_lgbm_model, rep_bb = balanced_bagging_lgbm(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_balanced_bagging_lgbm_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(balanced_bagging_lgbm_model, f)\n",
    "\n",
    "    lgbm_imbalance_model, rep_lgbm_imbalance = lgbm_imbalance(df_train.copy(), df_test.copy(),target_col,dataset_name)\n",
    "    print(\"Saving model as pickle...\")\n",
    "    with open(\"{}_lgbm_imbalance_model.pkl\".format(dataset_name), \"wb\") as f:\n",
    "        pickle.dump(lgbm_imbalance_model, f)\n",
    "\n",
    "    return pd.DataFrame([rep_lgbm_base,rep_upsample,rep_downsample,rep_smote_lgbm,rep_bb,rep_lgbm_imbalance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4b980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
